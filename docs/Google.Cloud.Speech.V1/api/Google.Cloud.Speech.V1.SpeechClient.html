<!DOCTYPE html>
<!--[if IE]><![endif]-->
<html>
  
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>Class SpeechClient
   | Google.Cloud.Speech.V1 </title>
    <meta name="viewport" content="width=device-width">
    <meta name="title" content="Class SpeechClient
   | Google.Cloud.Speech.V1 ">
    <meta name="generator" content="docfx 2.18.5.0">
    
    <link rel="shortcut icon" href="../favicon.ico">
    <link rel="stylesheet" href="../styles/docfx.vendor.css">
    <link rel="stylesheet" href="../styles/docfx.css">
    <link rel="stylesheet" href="../styles/main.css">
    <meta property="docfx:navrel" content="../toc.html">
    <meta property="docfx:tocrel" content="toc.html">
    
    
  </head>
  <body data-spy="scroll" data-target="#affix">
    <div id="wrapper">
      <header>
        
        <nav id="autocollapse" class="navbar navbar-inverse ng-scope" role="navigation">
          <div class="container">
            <div class="navbar-header">
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
              
              <a class="navbar-brand" href="../index.html">
                <img id="logo" class="svg" src="../logo.svg" alt="">
              </a>
            </div>
            <div class="collapse navbar-collapse" id="navbar">
              <form class="navbar-form navbar-right" role="search" id="search">
                <div class="form-group">
                  <input type="text" class="form-control" id="search-query" placeholder="Search" autocomplete="off">
                </div>
              </form>
            </div>
          </div>
        </nav>
        
        <div class="subnav navbar navbar-default">
          <div class="container hide-when-search" id="breadcrumb">
            <ul class="breadcrumb">
              <li></li>
            </ul>
          </div>
        </div>
      </header>
      <div role="main" class="container body-content hide-when-search">
        
        <div class="sidenav hide-when-search">
          <a class="btn toc-toggle collapse" data-toggle="collapse" href="#sidetoggle" aria-expanded="false" aria-controls="sidetoggle">Show / Hide Table of Contents</a>
          <div class="sidetoggle collapse" id="sidetoggle">
            <div id="sidetoc"></div>
          </div>
        </div>
        <div class="article row grid-right">
          <div class="col-md-10">
            <article class="content wrap" id="_content" data-uid="Google.Cloud.Speech.V1.SpeechClient">
  
  
  <h1 id="Google_Cloud_Speech_V1_SpeechClient" data-uid="Google.Cloud.Speech.V1.SpeechClient">Class SpeechClient
  </h1>
  <div class="markdown level0 summary"><p>Speech client wrapper, for convenient use.</p>
</div>
  <div class="markdown level0 conceptual"></div>
  <div class="inheritance">
    <h5>Inheritance</h5>
    <div class="level0"><span class="xref">System.Object</span></div>
    <div class="level1"><span class="xref">SpeechClient</span></div>
  </div>
      <div class="level2"><a class="xref" href="Google.Cloud.Speech.V1.SpeechClientImpl.html">SpeechClientImpl</a></div>
  <div class="inheritedMembers">
    <h5>Inherited Members</h5>
    <div>
      <span class="xref">System.Object.ToString()</span>
    </div>
    <div>
      <span class="xref">System.Object.GetHashCode()</span>
    </div>
    <div>
      <span class="xref">System.Object.GetType()</span>
    </div>
    <div>
      <span class="xref">System.Object.MemberwiseClone()</span>
    </div>
  </div>
  <h6><strong>Namespace</strong>: <a class="xref" href="Google.Cloud.Speech.V1.html">Google.Cloud.Speech.V1</a></h6>
  <h6><strong>Assembly</strong>: Google.Cloud.Speech.V1.dll</h6>
  <h5 id="Google_Cloud_Speech_V1_SpeechClient_syntax">Syntax</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public abstract class SpeechClient</code></pre>
  </div>
  <h3 id="properties">Properties
  </h3>
  <a id="Google_Cloud_Speech_V1_SpeechClient_DefaultEndpoint_" data-uid="Google.Cloud.Speech.V1.SpeechClient.DefaultEndpoint*"></a>
  <h4 id="Google_Cloud_Speech_V1_SpeechClient_DefaultEndpoint" data-uid="Google.Cloud.Speech.V1.SpeechClient.DefaultEndpoint">DefaultEndpoint</h4>
  <div class="markdown level1 summary"><p>The default endpoint for the Speech service, which is a host of &quot;speech.googleapis.com&quot; and a port of 443.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static ServiceEndpoint DefaultEndpoint { get; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.Api.Gax.Grpc.ServiceEndpoint.html">ServiceEndpoint</a></td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <a id="Google_Cloud_Speech_V1_SpeechClient_DefaultScopes_" data-uid="Google.Cloud.Speech.V1.SpeechClient.DefaultScopes*"></a>
  <h4 id="Google_Cloud_Speech_V1_SpeechClient_DefaultScopes" data-uid="Google.Cloud.Speech.V1.SpeechClient.DefaultScopes">DefaultScopes</h4>
  <div class="markdown level1 summary"><p>The default Speech scopes.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static IReadOnlyList&lt;string&gt; DefaultScopes { get; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Collections.Generic.IReadOnlyList</span>&lt;<span class="xref">System.String</span>&gt;</td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <h5 id="Google_Cloud_Speech_V1_SpeechClient_DefaultScopes_remarks">Remarks</h5>
  <div class="markdown level1 remarks"><p>The default Speech scopes are:
<ul><li>&quot;<a href="https://www.googleapis.com/auth/cloud-platform">https://www.googleapis.com/auth/cloud-platform</a>&quot;</li></ul></p>
</div>
  <a id="Google_Cloud_Speech_V1_SpeechClient_GrpcClient_" data-uid="Google.Cloud.Speech.V1.SpeechClient.GrpcClient*"></a>
  <h4 id="Google_Cloud_Speech_V1_SpeechClient_GrpcClient" data-uid="Google.Cloud.Speech.V1.SpeechClient.GrpcClient">GrpcClient</h4>
  <div class="markdown level1 summary"><p>The underlying gRPC Speech client.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual Speech.SpeechClient GrpcClient { get; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.Speech.SpeechClient.html">Speech.SpeechClient</a></td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <a id="Google_Cloud_Speech_V1_SpeechClient_LongRunningOperationsClient_" data-uid="Google.Cloud.Speech.V1.SpeechClient.LongRunningOperationsClient*"></a>
  <h4 id="Google_Cloud_Speech_V1_SpeechClient_LongRunningOperationsClient" data-uid="Google.Cloud.Speech.V1.SpeechClient.LongRunningOperationsClient">LongRunningOperationsClient</h4>
  <div class="markdown level1 summary"><p>The client for long-running operations.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual OperationsClient LongRunningOperationsClient { get; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.LongRunning.OperationsClient.html">OperationsClient</a></td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <h3 id="methods">Methods
  </h3>
  <a id="Google_Cloud_Speech_V1_SpeechClient_Create_" data-uid="Google.Cloud.Speech.V1.SpeechClient.Create*"></a>
  <h4 id="Google_Cloud_Speech_V1_SpeechClient_Create_Google_Api_Gax_Grpc_ServiceEndpoint_Google_Cloud_Speech_V1_SpeechSettings_" data-uid="Google.Cloud.Speech.V1.SpeechClient.Create(Google.Api.Gax.Grpc.ServiceEndpoint,Google.Cloud.Speech.V1.SpeechSettings)">Create(ServiceEndpoint, SpeechSettings)</h4>
  <div class="markdown level1 summary"><p>Synchronously creates a <a class="xref" href="Google.Cloud.Speech.V1.SpeechClient.html">SpeechClient</a>, applying defaults for all unspecified settings,
and creating a channel connecting to the given endpoint with application default credentials where
necessary.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static SpeechClient Create(ServiceEndpoint endpoint = null, SpeechSettings settings = null)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.Api.Gax.Grpc.ServiceEndpoint.html">ServiceEndpoint</a></td>
        <td><span class="parametername">endpoint</span></td>
        <td><p>Optional <a class="xref" href="Google.Api.Gax.Grpc.ServiceEndpoint.html">ServiceEndpoint</a>.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.SpeechSettings.html">SpeechSettings</a></td>
        <td><span class="parametername">settings</span></td>
        <td><p>Optional <a class="xref" href="Google.Cloud.Speech.V1.SpeechSettings.html">SpeechSettings</a>.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.SpeechClient.html">SpeechClient</a></td>
        <td><p>The created <a class="xref" href="Google.Cloud.Speech.V1.SpeechClient.html">SpeechClient</a>.</p>
</td>
      </tr>
    </tbody>
  </table>
  <a id="Google_Cloud_Speech_V1_SpeechClient_Create_" data-uid="Google.Cloud.Speech.V1.SpeechClient.Create*"></a>
  <h4 id="Google_Cloud_Speech_V1_SpeechClient_Create_Grpc_Core_Channel_Google_Cloud_Speech_V1_SpeechSettings_" data-uid="Google.Cloud.Speech.V1.SpeechClient.Create(Grpc.Core.Channel,Google.Cloud.Speech.V1.SpeechSettings)">Create(Channel, SpeechSettings)</h4>
  <div class="markdown level1 summary"><p>Creates a <a class="xref" href="Google.Cloud.Speech.V1.SpeechClient.html">SpeechClient</a> which uses the specified channel for remote operations.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static SpeechClient Create(Channel channel, SpeechSettings settings = null)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Grpc.Core.Channel.html">Channel</a></td>
        <td><span class="parametername">channel</span></td>
        <td><p>The <a class="xref" href="Grpc.Core.Channel.html">Channel</a> for remote operations. Must not be null.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.SpeechSettings.html">SpeechSettings</a></td>
        <td><span class="parametername">settings</span></td>
        <td><p>Optional <a class="xref" href="Google.Cloud.Speech.V1.SpeechSettings.html">SpeechSettings</a>.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.SpeechClient.html">SpeechClient</a></td>
        <td><p>The created <a class="xref" href="Google.Cloud.Speech.V1.SpeechClient.html">SpeechClient</a>.</p>
</td>
      </tr>
    </tbody>
  </table>
  <a id="Google_Cloud_Speech_V1_SpeechClient_CreateAsync_" data-uid="Google.Cloud.Speech.V1.SpeechClient.CreateAsync*"></a>
  <h4 id="Google_Cloud_Speech_V1_SpeechClient_CreateAsync_Google_Api_Gax_Grpc_ServiceEndpoint_Google_Cloud_Speech_V1_SpeechSettings_" data-uid="Google.Cloud.Speech.V1.SpeechClient.CreateAsync(Google.Api.Gax.Grpc.ServiceEndpoint,Google.Cloud.Speech.V1.SpeechSettings)">CreateAsync(ServiceEndpoint, SpeechSettings)</h4>
  <div class="markdown level1 summary"><p>Asynchronously creates a <a class="xref" href="Google.Cloud.Speech.V1.SpeechClient.html">SpeechClient</a>, applying defaults for all unspecified settings,
and creating a channel connecting to the given endpoint with application default credentials where
necessary.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static Task&lt;SpeechClient&gt; CreateAsync(ServiceEndpoint endpoint = null, SpeechSettings settings = null)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.Api.Gax.Grpc.ServiceEndpoint.html">ServiceEndpoint</a></td>
        <td><span class="parametername">endpoint</span></td>
        <td><p>Optional <a class="xref" href="Google.Api.Gax.Grpc.ServiceEndpoint.html">ServiceEndpoint</a>.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.SpeechSettings.html">SpeechSettings</a></td>
        <td><span class="parametername">settings</span></td>
        <td><p>Optional <a class="xref" href="Google.Cloud.Speech.V1.SpeechSettings.html">SpeechSettings</a>.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Threading.Tasks.Task</span>&lt;<a class="xref" href="Google.Cloud.Speech.V1.SpeechClient.html">SpeechClient</a>&gt;</td>
        <td><p>The task representing the created <a class="xref" href="Google.Cloud.Speech.V1.SpeechClient.html">SpeechClient</a>.</p>
</td>
      </tr>
    </tbody>
  </table>
  <a id="Google_Cloud_Speech_V1_SpeechClient_LongRunningRecognize_" data-uid="Google.Cloud.Speech.V1.SpeechClient.LongRunningRecognize*"></a>
  <h4 id="Google_Cloud_Speech_V1_SpeechClient_LongRunningRecognize_Google_Cloud_Speech_V1_LongRunningRecognizeRequest_Google_Api_Gax_Grpc_CallSettings_" data-uid="Google.Cloud.Speech.V1.SpeechClient.LongRunningRecognize(Google.Cloud.Speech.V1.LongRunningRecognizeRequest,Google.Api.Gax.Grpc.CallSettings)">LongRunningRecognize(LongRunningRecognizeRequest, CallSettings)</h4>
  <div class="markdown level1 summary"><p>Performs asynchronous speech recognition: receive results via the
google.longrunning.Operations interface. Returns either an
<code>Operation.error</code> or an <code>Operation.response</code> which contains
a <code>LongRunningRecognizeResponse</code> message.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual Operation&lt;LongRunningRecognizeResponse, LongRunningRecognizeMetadata&gt; LongRunningRecognize(LongRunningRecognizeRequest request, CallSettings callSettings = null)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.LongRunningRecognizeRequest.html">LongRunningRecognizeRequest</a></td>
        <td><span class="parametername">request</span></td>
        <td><p>The request object containing all of the parameters for the API call.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="Google.Api.Gax.Grpc.CallSettings.html">CallSettings</a></td>
        <td><span class="parametername">callSettings</span></td>
        <td><p>If not null, applies overrides to this RPC call.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.LongRunning.Operation-2.html">Operation</a>&lt;<a class="xref" href="Google.Cloud.Speech.V1.LongRunningRecognizeResponse.html">LongRunningRecognizeResponse</a>, <a class="xref" href="Google.Cloud.Speech.V1.LongRunningRecognizeMetadata.html">LongRunningRecognizeMetadata</a>&gt;</td>
        <td><p>The RPC response.</p>
</td>
      </tr>
    </tbody>
  </table>
  <div>
  <h5 id="Google_Cloud_Speech_V1_SpeechClient_LongRunningRecognize_Google_Cloud_Speech_V1_LongRunningRecognizeRequest_Google_Api_Gax_Grpc_CallSettings__snippet">Sample code</h5>
  <div class="markdown level1"><pre><code class="lang-cs">// Create client
SpeechClient speechClient = SpeechClient.Create();
// Initialize request argument(s)
LongRunningRecognizeRequest request = new LongRunningRecognizeRequest
{
    Config = new RecognitionConfig
             {
                 Encoding = RecognitionConfig.Types.AudioEncoding.Flac,
                 SampleRateHertz = 44100,
                 LanguageCode = &quot;en-US&quot;,
             },
    Audio = new RecognitionAudio
            {
                Uri = &quot;gs://bucket_name/file_name.flac&quot;,
            },
};
// Make the request
Operation&lt;LongRunningRecognizeResponse, LongRunningRecognizeMetadata&gt; response =
    speechClient.LongRunningRecognize(request);

// Poll until the returned long-running operation is complete
Operation&lt;LongRunningRecognizeResponse, LongRunningRecognizeMetadata&gt; completedResponse =
    response.PollUntilCompleted();
// Retrieve the operation result
LongRunningRecognizeResponse result = completedResponse.Result;

// Or get the name of the operation
string operationName = response.Name;
// This name can be stored, then the long-running operation retrieved later by name
Operation&lt;LongRunningRecognizeResponse, LongRunningRecognizeMetadata&gt; retrievedResponse =
    speechClient.PollOnceLongRunningRecognize(operationName);
// Check if the retrieved long-running operation has completed
if (retrievedResponse.IsCompleted)
{
    // If it has completed, then access the result
    LongRunningRecognizeResponse retrievedResult = retrievedResponse.Result;
}
</code></pre></div>
  </div>
  <a id="Google_Cloud_Speech_V1_SpeechClient_LongRunningRecognize_" data-uid="Google.Cloud.Speech.V1.SpeechClient.LongRunningRecognize*"></a>
  <h4 id="Google_Cloud_Speech_V1_SpeechClient_LongRunningRecognize_Google_Cloud_Speech_V1_RecognitionConfig_Google_Cloud_Speech_V1_RecognitionAudio_Google_Api_Gax_Grpc_CallSettings_" data-uid="Google.Cloud.Speech.V1.SpeechClient.LongRunningRecognize(Google.Cloud.Speech.V1.RecognitionConfig,Google.Cloud.Speech.V1.RecognitionAudio,Google.Api.Gax.Grpc.CallSettings)">LongRunningRecognize(RecognitionConfig, RecognitionAudio, CallSettings)</h4>
  <div class="markdown level1 summary"><p>Performs asynchronous speech recognition: receive results via the
google.longrunning.Operations interface. Returns either an
<code>Operation.error</code> or an <code>Operation.response</code> which contains
a <code>LongRunningRecognizeResponse</code> message.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual Operation&lt;LongRunningRecognizeResponse, LongRunningRecognizeMetadata&gt; LongRunningRecognize(RecognitionConfig config, RecognitionAudio audio, CallSettings callSettings = null)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.RecognitionConfig.html">RecognitionConfig</a></td>
        <td><span class="parametername">config</span></td>
        <td><p><em>Required</em> Provides information to the recognizer that specifies how to
process the request.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.RecognitionAudio.html">RecognitionAudio</a></td>
        <td><span class="parametername">audio</span></td>
        <td><p><em>Required</em> The audio data to be recognized.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="Google.Api.Gax.Grpc.CallSettings.html">CallSettings</a></td>
        <td><span class="parametername">callSettings</span></td>
        <td><p>If not null, applies overrides to this RPC call.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.LongRunning.Operation-2.html">Operation</a>&lt;<a class="xref" href="Google.Cloud.Speech.V1.LongRunningRecognizeResponse.html">LongRunningRecognizeResponse</a>, <a class="xref" href="Google.Cloud.Speech.V1.LongRunningRecognizeMetadata.html">LongRunningRecognizeMetadata</a>&gt;</td>
        <td><p>The RPC response.</p>
</td>
      </tr>
    </tbody>
  </table>
  <div>
  <h5 id="Google_Cloud_Speech_V1_SpeechClient_LongRunningRecognize_Google_Cloud_Speech_V1_RecognitionConfig_Google_Cloud_Speech_V1_RecognitionAudio_Google_Api_Gax_Grpc_CallSettings__snippet">Sample code</h5>
  <div class="markdown level1"><pre><code class="lang-cs">// Create client
SpeechClient speechClient = SpeechClient.Create();
// Initialize request argument(s)
RecognitionConfig config = new RecognitionConfig
{
    Encoding = RecognitionConfig.Types.AudioEncoding.Flac,
    SampleRateHertz = 44100,
    LanguageCode = &quot;en-US&quot;,
};
RecognitionAudio audio = new RecognitionAudio
{
    Uri = &quot;gs://bucket_name/file_name.flac&quot;,
};
// Make the request
Operation&lt;LongRunningRecognizeResponse, LongRunningRecognizeMetadata&gt; response =
    speechClient.LongRunningRecognize(config, audio);

// Poll until the returned long-running operation is complete
Operation&lt;LongRunningRecognizeResponse, LongRunningRecognizeMetadata&gt; completedResponse =
    response.PollUntilCompleted();
// Retrieve the operation result
LongRunningRecognizeResponse result = completedResponse.Result;

// Or get the name of the operation
string operationName = response.Name;
// This name can be stored, then the long-running operation retrieved later by name
Operation&lt;LongRunningRecognizeResponse, LongRunningRecognizeMetadata&gt; retrievedResponse =
    speechClient.PollOnceLongRunningRecognize(operationName);
// Check if the retrieved long-running operation has completed
if (retrievedResponse.IsCompleted)
{
    // If it has completed, then access the result
    LongRunningRecognizeResponse retrievedResult = retrievedResponse.Result;
}
</code></pre></div>
  </div>
  <a id="Google_Cloud_Speech_V1_SpeechClient_LongRunningRecognizeAsync_" data-uid="Google.Cloud.Speech.V1.SpeechClient.LongRunningRecognizeAsync*"></a>
  <h4 id="Google_Cloud_Speech_V1_SpeechClient_LongRunningRecognizeAsync_Google_Cloud_Speech_V1_LongRunningRecognizeRequest_Google_Api_Gax_Grpc_CallSettings_" data-uid="Google.Cloud.Speech.V1.SpeechClient.LongRunningRecognizeAsync(Google.Cloud.Speech.V1.LongRunningRecognizeRequest,Google.Api.Gax.Grpc.CallSettings)">LongRunningRecognizeAsync(LongRunningRecognizeRequest, CallSettings)</h4>
  <div class="markdown level1 summary"><p>Performs asynchronous speech recognition: receive results via the
google.longrunning.Operations interface. Returns either an
<code>Operation.error</code> or an <code>Operation.response</code> which contains
a <code>LongRunningRecognizeResponse</code> message.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual Task&lt;Operation&lt;LongRunningRecognizeResponse, LongRunningRecognizeMetadata&gt;&gt; LongRunningRecognizeAsync(LongRunningRecognizeRequest request, CallSettings callSettings = null)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.LongRunningRecognizeRequest.html">LongRunningRecognizeRequest</a></td>
        <td><span class="parametername">request</span></td>
        <td><p>The request object containing all of the parameters for the API call.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="Google.Api.Gax.Grpc.CallSettings.html">CallSettings</a></td>
        <td><span class="parametername">callSettings</span></td>
        <td><p>If not null, applies overrides to this RPC call.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Threading.Tasks.Task</span>&lt;<a class="xref" href="Google.LongRunning.Operation-2.html">Operation</a>&lt;<a class="xref" href="Google.Cloud.Speech.V1.LongRunningRecognizeResponse.html">LongRunningRecognizeResponse</a>, <a class="xref" href="Google.Cloud.Speech.V1.LongRunningRecognizeMetadata.html">LongRunningRecognizeMetadata</a>&gt;&gt;</td>
        <td><p>A Task containing the RPC response.</p>
</td>
      </tr>
    </tbody>
  </table>
  <div>
  <h5 id="Google_Cloud_Speech_V1_SpeechClient_LongRunningRecognizeAsync_Google_Cloud_Speech_V1_LongRunningRecognizeRequest_Google_Api_Gax_Grpc_CallSettings__snippet">Sample code</h5>
  <div class="markdown level1"><pre><code class="lang-cs">// Create client
SpeechClient speechClient = await SpeechClient.CreateAsync();
// Initialize request argument(s)
LongRunningRecognizeRequest request = new LongRunningRecognizeRequest
{
    Config = new RecognitionConfig
             {
                 Encoding = RecognitionConfig.Types.AudioEncoding.Flac,
                 SampleRateHertz = 44100,
                 LanguageCode = &quot;en-US&quot;,
             },
    Audio = new RecognitionAudio
            {
                Uri = &quot;gs://bucket_name/file_name.flac&quot;,
            },
};
// Make the request
Operation&lt;LongRunningRecognizeResponse, LongRunningRecognizeMetadata&gt; response =
    await speechClient.LongRunningRecognizeAsync(request);

// Poll until the returned long-running operation is complete
Operation&lt;LongRunningRecognizeResponse, LongRunningRecognizeMetadata&gt; completedResponse =
    await response.PollUntilCompletedAsync();
// Retrieve the operation result
LongRunningRecognizeResponse result = completedResponse.Result;

// Or get the name of the operation
string operationName = response.Name;
// This name can be stored, then the long-running operation retrieved later by name
Operation&lt;LongRunningRecognizeResponse, LongRunningRecognizeMetadata&gt; retrievedResponse =
    await speechClient.PollOnceLongRunningRecognizeAsync(operationName);
// Check if the retrieved long-running operation has completed
if (retrievedResponse.IsCompleted)
{
    // If it has completed, then access the result
    LongRunningRecognizeResponse retrievedResult = retrievedResponse.Result;
}
</code></pre></div>
  </div>
  <a id="Google_Cloud_Speech_V1_SpeechClient_LongRunningRecognizeAsync_" data-uid="Google.Cloud.Speech.V1.SpeechClient.LongRunningRecognizeAsync*"></a>
  <h4 id="Google_Cloud_Speech_V1_SpeechClient_LongRunningRecognizeAsync_Google_Cloud_Speech_V1_RecognitionConfig_Google_Cloud_Speech_V1_RecognitionAudio_Google_Api_Gax_Grpc_CallSettings_" data-uid="Google.Cloud.Speech.V1.SpeechClient.LongRunningRecognizeAsync(Google.Cloud.Speech.V1.RecognitionConfig,Google.Cloud.Speech.V1.RecognitionAudio,Google.Api.Gax.Grpc.CallSettings)">LongRunningRecognizeAsync(RecognitionConfig, RecognitionAudio, CallSettings)</h4>
  <div class="markdown level1 summary"><p>Performs asynchronous speech recognition: receive results via the
google.longrunning.Operations interface. Returns either an
<code>Operation.error</code> or an <code>Operation.response</code> which contains
a <code>LongRunningRecognizeResponse</code> message.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual Task&lt;Operation&lt;LongRunningRecognizeResponse, LongRunningRecognizeMetadata&gt;&gt; LongRunningRecognizeAsync(RecognitionConfig config, RecognitionAudio audio, CallSettings callSettings = null)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.RecognitionConfig.html">RecognitionConfig</a></td>
        <td><span class="parametername">config</span></td>
        <td><p><em>Required</em> Provides information to the recognizer that specifies how to
process the request.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.RecognitionAudio.html">RecognitionAudio</a></td>
        <td><span class="parametername">audio</span></td>
        <td><p><em>Required</em> The audio data to be recognized.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="Google.Api.Gax.Grpc.CallSettings.html">CallSettings</a></td>
        <td><span class="parametername">callSettings</span></td>
        <td><p>If not null, applies overrides to this RPC call.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Threading.Tasks.Task</span>&lt;<a class="xref" href="Google.LongRunning.Operation-2.html">Operation</a>&lt;<a class="xref" href="Google.Cloud.Speech.V1.LongRunningRecognizeResponse.html">LongRunningRecognizeResponse</a>, <a class="xref" href="Google.Cloud.Speech.V1.LongRunningRecognizeMetadata.html">LongRunningRecognizeMetadata</a>&gt;&gt;</td>
        <td><p>A Task containing the RPC response.</p>
</td>
      </tr>
    </tbody>
  </table>
  <div>
  <h5 id="Google_Cloud_Speech_V1_SpeechClient_LongRunningRecognizeAsync_Google_Cloud_Speech_V1_RecognitionConfig_Google_Cloud_Speech_V1_RecognitionAudio_Google_Api_Gax_Grpc_CallSettings__snippet">Sample code</h5>
  <div class="markdown level1"><pre><code class="lang-cs">// Create client
SpeechClient speechClient = await SpeechClient.CreateAsync();
// Initialize request argument(s)
RecognitionConfig config = new RecognitionConfig
{
    Encoding = RecognitionConfig.Types.AudioEncoding.Flac,
    SampleRateHertz = 44100,
    LanguageCode = &quot;en-US&quot;,
};
RecognitionAudio audio = new RecognitionAudio
{
    Uri = &quot;gs://bucket_name/file_name.flac&quot;,
};
// Make the request
Operation&lt;LongRunningRecognizeResponse, LongRunningRecognizeMetadata&gt; response =
    await speechClient.LongRunningRecognizeAsync(config, audio);

// Poll until the returned long-running operation is complete
Operation&lt;LongRunningRecognizeResponse, LongRunningRecognizeMetadata&gt; completedResponse =
    await response.PollUntilCompletedAsync();
// Retrieve the operation result
LongRunningRecognizeResponse result = completedResponse.Result;

// Or get the name of the operation
string operationName = response.Name;
// This name can be stored, then the long-running operation retrieved later by name
Operation&lt;LongRunningRecognizeResponse, LongRunningRecognizeMetadata&gt; retrievedResponse =
    await speechClient.PollOnceLongRunningRecognizeAsync(operationName);
// Check if the retrieved long-running operation has completed
if (retrievedResponse.IsCompleted)
{
    // If it has completed, then access the result
    LongRunningRecognizeResponse retrievedResult = retrievedResponse.Result;
}
</code></pre></div>
  </div>
  <a id="Google_Cloud_Speech_V1_SpeechClient_LongRunningRecognizeAsync_" data-uid="Google.Cloud.Speech.V1.SpeechClient.LongRunningRecognizeAsync*"></a>
  <h4 id="Google_Cloud_Speech_V1_SpeechClient_LongRunningRecognizeAsync_Google_Cloud_Speech_V1_RecognitionConfig_Google_Cloud_Speech_V1_RecognitionAudio_System_Threading_CancellationToken_" data-uid="Google.Cloud.Speech.V1.SpeechClient.LongRunningRecognizeAsync(Google.Cloud.Speech.V1.RecognitionConfig,Google.Cloud.Speech.V1.RecognitionAudio,System.Threading.CancellationToken)">LongRunningRecognizeAsync(RecognitionConfig, RecognitionAudio, CancellationToken)</h4>
  <div class="markdown level1 summary"><p>Performs asynchronous speech recognition: receive results via the
google.longrunning.Operations interface. Returns either an
<code>Operation.error</code> or an <code>Operation.response</code> which contains
a <code>LongRunningRecognizeResponse</code> message.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual Task&lt;Operation&lt;LongRunningRecognizeResponse, LongRunningRecognizeMetadata&gt;&gt; LongRunningRecognizeAsync(RecognitionConfig config, RecognitionAudio audio, CancellationToken cancellationToken)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.RecognitionConfig.html">RecognitionConfig</a></td>
        <td><span class="parametername">config</span></td>
        <td><p><em>Required</em> Provides information to the recognizer that specifies how to
process the request.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.RecognitionAudio.html">RecognitionAudio</a></td>
        <td><span class="parametername">audio</span></td>
        <td><p><em>Required</em> The audio data to be recognized.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Threading.CancellationToken</span></td>
        <td><span class="parametername">cancellationToken</span></td>
        <td><p>A <span class="xref">System.Threading.CancellationToken</span> to use for this RPC.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Threading.Tasks.Task</span>&lt;<a class="xref" href="Google.LongRunning.Operation-2.html">Operation</a>&lt;<a class="xref" href="Google.Cloud.Speech.V1.LongRunningRecognizeResponse.html">LongRunningRecognizeResponse</a>, <a class="xref" href="Google.Cloud.Speech.V1.LongRunningRecognizeMetadata.html">LongRunningRecognizeMetadata</a>&gt;&gt;</td>
        <td><p>A Task containing the RPC response.</p>
</td>
      </tr>
    </tbody>
  </table>
  <div>
  <h5 id="Google_Cloud_Speech_V1_SpeechClient_LongRunningRecognizeAsync_Google_Cloud_Speech_V1_RecognitionConfig_Google_Cloud_Speech_V1_RecognitionAudio_System_Threading_CancellationToken__snippet">Sample code</h5>
  <div class="markdown level1"><pre><code class="lang-cs">// Create client
SpeechClient speechClient = await SpeechClient.CreateAsync();
// Initialize request argument(s)
RecognitionConfig config = new RecognitionConfig
{
    Encoding = RecognitionConfig.Types.AudioEncoding.Flac,
    SampleRateHertz = 44100,
    LanguageCode = &quot;en-US&quot;,
};
RecognitionAudio audio = new RecognitionAudio
{
    Uri = &quot;gs://bucket_name/file_name.flac&quot;,
};
// Make the request
Operation&lt;LongRunningRecognizeResponse, LongRunningRecognizeMetadata&gt; response =
    await speechClient.LongRunningRecognizeAsync(config, audio);

// Poll until the returned long-running operation is complete
Operation&lt;LongRunningRecognizeResponse, LongRunningRecognizeMetadata&gt; completedResponse =
    await response.PollUntilCompletedAsync();
// Retrieve the operation result
LongRunningRecognizeResponse result = completedResponse.Result;

// Or get the name of the operation
string operationName = response.Name;
// This name can be stored, then the long-running operation retrieved later by name
Operation&lt;LongRunningRecognizeResponse, LongRunningRecognizeMetadata&gt; retrievedResponse =
    await speechClient.PollOnceLongRunningRecognizeAsync(operationName);
// Check if the retrieved long-running operation has completed
if (retrievedResponse.IsCompleted)
{
    // If it has completed, then access the result
    LongRunningRecognizeResponse retrievedResult = retrievedResponse.Result;
}
</code></pre></div>
  </div>
  <a id="Google_Cloud_Speech_V1_SpeechClient_PollOnceLongRunningRecognize_" data-uid="Google.Cloud.Speech.V1.SpeechClient.PollOnceLongRunningRecognize*"></a>
  <h4 id="Google_Cloud_Speech_V1_SpeechClient_PollOnceLongRunningRecognize_System_String_Google_Api_Gax_Grpc_CallSettings_" data-uid="Google.Cloud.Speech.V1.SpeechClient.PollOnceLongRunningRecognize(System.String,Google.Api.Gax.Grpc.CallSettings)">PollOnceLongRunningRecognize(String, CallSettings)</h4>
  <div class="markdown level1 summary"><p>Poll an operation once, using an <code>operationName</code> from a previous invocation of <code>LongRunningRecognize</code>.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual Operation&lt;LongRunningRecognizeResponse, LongRunningRecognizeMetadata&gt; PollOnceLongRunningRecognize(string operationName, CallSettings callSettings = null)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.String</span></td>
        <td><span class="parametername">operationName</span></td>
        <td><p>The name of a previously invoked operation. Must not be <code>null</code> or empty.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="Google.Api.Gax.Grpc.CallSettings.html">CallSettings</a></td>
        <td><span class="parametername">callSettings</span></td>
        <td><p>If not null, applies overrides to this RPC call.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.LongRunning.Operation-2.html">Operation</a>&lt;<a class="xref" href="Google.Cloud.Speech.V1.LongRunningRecognizeResponse.html">LongRunningRecognizeResponse</a>, <a class="xref" href="Google.Cloud.Speech.V1.LongRunningRecognizeMetadata.html">LongRunningRecognizeMetadata</a>&gt;</td>
        <td><p>The result of polling the operation.</p>
</td>
      </tr>
    </tbody>
  </table>
  <a id="Google_Cloud_Speech_V1_SpeechClient_PollOnceLongRunningRecognizeAsync_" data-uid="Google.Cloud.Speech.V1.SpeechClient.PollOnceLongRunningRecognizeAsync*"></a>
  <h4 id="Google_Cloud_Speech_V1_SpeechClient_PollOnceLongRunningRecognizeAsync_System_String_Google_Api_Gax_Grpc_CallSettings_" data-uid="Google.Cloud.Speech.V1.SpeechClient.PollOnceLongRunningRecognizeAsync(System.String,Google.Api.Gax.Grpc.CallSettings)">PollOnceLongRunningRecognizeAsync(String, CallSettings)</h4>
  <div class="markdown level1 summary"><p>Asynchronously poll an operation once, using an <code>operationName</code> from a previous invocation of <code>LongRunningRecognizeAsync</code>.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual Task&lt;Operation&lt;LongRunningRecognizeResponse, LongRunningRecognizeMetadata&gt;&gt; PollOnceLongRunningRecognizeAsync(string operationName, CallSettings callSettings = null)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.String</span></td>
        <td><span class="parametername">operationName</span></td>
        <td><p>The name of a previously invoked operation. Must not be <code>null</code> or empty.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="Google.Api.Gax.Grpc.CallSettings.html">CallSettings</a></td>
        <td><span class="parametername">callSettings</span></td>
        <td><p>If not null, applies overrides to this RPC call.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Threading.Tasks.Task</span>&lt;<a class="xref" href="Google.LongRunning.Operation-2.html">Operation</a>&lt;<a class="xref" href="Google.Cloud.Speech.V1.LongRunningRecognizeResponse.html">LongRunningRecognizeResponse</a>, <a class="xref" href="Google.Cloud.Speech.V1.LongRunningRecognizeMetadata.html">LongRunningRecognizeMetadata</a>&gt;&gt;</td>
        <td><p>A task representing the result of polling the operation.</p>
</td>
      </tr>
    </tbody>
  </table>
  <a id="Google_Cloud_Speech_V1_SpeechClient_Recognize_" data-uid="Google.Cloud.Speech.V1.SpeechClient.Recognize*"></a>
  <h4 id="Google_Cloud_Speech_V1_SpeechClient_Recognize_Google_Cloud_Speech_V1_RecognitionConfig_Google_Cloud_Speech_V1_RecognitionAudio_Google_Api_Gax_Grpc_CallSettings_" data-uid="Google.Cloud.Speech.V1.SpeechClient.Recognize(Google.Cloud.Speech.V1.RecognitionConfig,Google.Cloud.Speech.V1.RecognitionAudio,Google.Api.Gax.Grpc.CallSettings)">Recognize(RecognitionConfig, RecognitionAudio, CallSettings)</h4>
  <div class="markdown level1 summary"><p>Performs synchronous speech recognition: receive results after all audio
has been sent and processed.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual RecognizeResponse Recognize(RecognitionConfig config, RecognitionAudio audio, CallSettings callSettings = null)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.RecognitionConfig.html">RecognitionConfig</a></td>
        <td><span class="parametername">config</span></td>
        <td><p><em>Required</em> Provides information to the recognizer that specifies how to
process the request.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.RecognitionAudio.html">RecognitionAudio</a></td>
        <td><span class="parametername">audio</span></td>
        <td><p><em>Required</em> The audio data to be recognized.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="Google.Api.Gax.Grpc.CallSettings.html">CallSettings</a></td>
        <td><span class="parametername">callSettings</span></td>
        <td><p>If not null, applies overrides to this RPC call.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.RecognizeResponse.html">RecognizeResponse</a></td>
        <td><p>The RPC response.</p>
</td>
      </tr>
    </tbody>
  </table>
  <div>
  <h5 id="Google_Cloud_Speech_V1_SpeechClient_Recognize_Google_Cloud_Speech_V1_RecognitionConfig_Google_Cloud_Speech_V1_RecognitionAudio_Google_Api_Gax_Grpc_CallSettings__snippet">Sample code</h5>
  <div class="markdown level1"><pre><code class="lang-cs">SpeechClient client = SpeechClient.Create();
RecognitionConfig config = new RecognitionConfig
{
    Encoding = AudioEncoding.Linear16,
    SampleRateHertz = 16000,
    LanguageCode = LanguageCodes.English.UnitedStates
};
RecognizeResponse response = client.Recognize(config, audio);
Console.WriteLine(response);
</code></pre></div>
  </div>
  <a id="Google_Cloud_Speech_V1_SpeechClient_Recognize_" data-uid="Google.Cloud.Speech.V1.SpeechClient.Recognize*"></a>
  <h4 id="Google_Cloud_Speech_V1_SpeechClient_Recognize_Google_Cloud_Speech_V1_RecognizeRequest_Google_Api_Gax_Grpc_CallSettings_" data-uid="Google.Cloud.Speech.V1.SpeechClient.Recognize(Google.Cloud.Speech.V1.RecognizeRequest,Google.Api.Gax.Grpc.CallSettings)">Recognize(RecognizeRequest, CallSettings)</h4>
  <div class="markdown level1 summary"><p>Performs synchronous speech recognition: receive results after all audio
has been sent and processed.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual RecognizeResponse Recognize(RecognizeRequest request, CallSettings callSettings = null)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.RecognizeRequest.html">RecognizeRequest</a></td>
        <td><span class="parametername">request</span></td>
        <td><p>The request object containing all of the parameters for the API call.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="Google.Api.Gax.Grpc.CallSettings.html">CallSettings</a></td>
        <td><span class="parametername">callSettings</span></td>
        <td><p>If not null, applies overrides to this RPC call.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.RecognizeResponse.html">RecognizeResponse</a></td>
        <td><p>The RPC response.</p>
</td>
      </tr>
    </tbody>
  </table>
  <div>
  <h5 id="Google_Cloud_Speech_V1_SpeechClient_Recognize_Google_Cloud_Speech_V1_RecognizeRequest_Google_Api_Gax_Grpc_CallSettings__snippet">Sample code</h5>
  <div class="markdown level1"><pre><code class="lang-cs">// Create client
SpeechClient speechClient = SpeechClient.Create();
// Initialize request argument(s)
RecognizeRequest request = new RecognizeRequest
{
    Config = new RecognitionConfig
             {
                 Encoding = RecognitionConfig.Types.AudioEncoding.Flac,
                 SampleRateHertz = 44100,
                 LanguageCode = &quot;en-US&quot;,
             },
    Audio = new RecognitionAudio
            {
                Uri = &quot;gs://bucket_name/file_name.flac&quot;,
            },
};
// Make the request
RecognizeResponse response = speechClient.Recognize(request);
</code></pre></div>
  </div>
  <a id="Google_Cloud_Speech_V1_SpeechClient_RecognizeAsync_" data-uid="Google.Cloud.Speech.V1.SpeechClient.RecognizeAsync*"></a>
  <h4 id="Google_Cloud_Speech_V1_SpeechClient_RecognizeAsync_Google_Cloud_Speech_V1_RecognitionConfig_Google_Cloud_Speech_V1_RecognitionAudio_Google_Api_Gax_Grpc_CallSettings_" data-uid="Google.Cloud.Speech.V1.SpeechClient.RecognizeAsync(Google.Cloud.Speech.V1.RecognitionConfig,Google.Cloud.Speech.V1.RecognitionAudio,Google.Api.Gax.Grpc.CallSettings)">RecognizeAsync(RecognitionConfig, RecognitionAudio, CallSettings)</h4>
  <div class="markdown level1 summary"><p>Performs synchronous speech recognition: receive results after all audio
has been sent and processed.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual Task&lt;RecognizeResponse&gt; RecognizeAsync(RecognitionConfig config, RecognitionAudio audio, CallSettings callSettings = null)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.RecognitionConfig.html">RecognitionConfig</a></td>
        <td><span class="parametername">config</span></td>
        <td><p><em>Required</em> Provides information to the recognizer that specifies how to
process the request.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.RecognitionAudio.html">RecognitionAudio</a></td>
        <td><span class="parametername">audio</span></td>
        <td><p><em>Required</em> The audio data to be recognized.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="Google.Api.Gax.Grpc.CallSettings.html">CallSettings</a></td>
        <td><span class="parametername">callSettings</span></td>
        <td><p>If not null, applies overrides to this RPC call.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Threading.Tasks.Task</span>&lt;<a class="xref" href="Google.Cloud.Speech.V1.RecognizeResponse.html">RecognizeResponse</a>&gt;</td>
        <td><p>A Task containing the RPC response.</p>
</td>
      </tr>
    </tbody>
  </table>
  <div>
  <h5 id="Google_Cloud_Speech_V1_SpeechClient_RecognizeAsync_Google_Cloud_Speech_V1_RecognitionConfig_Google_Cloud_Speech_V1_RecognitionAudio_Google_Api_Gax_Grpc_CallSettings__snippet">Sample code</h5>
  <div class="markdown level1"><pre><code class="lang-cs">// Create client
SpeechClient speechClient = await SpeechClient.CreateAsync();
// Initialize request argument(s)
RecognitionConfig config = new RecognitionConfig
{
    Encoding = RecognitionConfig.Types.AudioEncoding.Flac,
    SampleRateHertz = 44100,
    LanguageCode = &quot;en-US&quot;,
};
RecognitionAudio audio = new RecognitionAudio
{
    Uri = &quot;gs://bucket_name/file_name.flac&quot;,
};
// Make the request
RecognizeResponse response = await speechClient.RecognizeAsync(config, audio);
</code></pre></div>
  </div>
  <a id="Google_Cloud_Speech_V1_SpeechClient_RecognizeAsync_" data-uid="Google.Cloud.Speech.V1.SpeechClient.RecognizeAsync*"></a>
  <h4 id="Google_Cloud_Speech_V1_SpeechClient_RecognizeAsync_Google_Cloud_Speech_V1_RecognitionConfig_Google_Cloud_Speech_V1_RecognitionAudio_System_Threading_CancellationToken_" data-uid="Google.Cloud.Speech.V1.SpeechClient.RecognizeAsync(Google.Cloud.Speech.V1.RecognitionConfig,Google.Cloud.Speech.V1.RecognitionAudio,System.Threading.CancellationToken)">RecognizeAsync(RecognitionConfig, RecognitionAudio, CancellationToken)</h4>
  <div class="markdown level1 summary"><p>Performs synchronous speech recognition: receive results after all audio
has been sent and processed.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual Task&lt;RecognizeResponse&gt; RecognizeAsync(RecognitionConfig config, RecognitionAudio audio, CancellationToken cancellationToken)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.RecognitionConfig.html">RecognitionConfig</a></td>
        <td><span class="parametername">config</span></td>
        <td><p><em>Required</em> Provides information to the recognizer that specifies how to
process the request.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.RecognitionAudio.html">RecognitionAudio</a></td>
        <td><span class="parametername">audio</span></td>
        <td><p><em>Required</em> The audio data to be recognized.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Threading.CancellationToken</span></td>
        <td><span class="parametername">cancellationToken</span></td>
        <td><p>A <span class="xref">System.Threading.CancellationToken</span> to use for this RPC.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Threading.Tasks.Task</span>&lt;<a class="xref" href="Google.Cloud.Speech.V1.RecognizeResponse.html">RecognizeResponse</a>&gt;</td>
        <td><p>A Task containing the RPC response.</p>
</td>
      </tr>
    </tbody>
  </table>
  <div>
  <h5 id="Google_Cloud_Speech_V1_SpeechClient_RecognizeAsync_Google_Cloud_Speech_V1_RecognitionConfig_Google_Cloud_Speech_V1_RecognitionAudio_System_Threading_CancellationToken__snippet">Sample code</h5>
  <div class="markdown level1"><pre><code class="lang-cs">// Create client
SpeechClient speechClient = await SpeechClient.CreateAsync();
// Initialize request argument(s)
RecognitionConfig config = new RecognitionConfig
{
    Encoding = RecognitionConfig.Types.AudioEncoding.Flac,
    SampleRateHertz = 44100,
    LanguageCode = &quot;en-US&quot;,
};
RecognitionAudio audio = new RecognitionAudio
{
    Uri = &quot;gs://bucket_name/file_name.flac&quot;,
};
// Make the request
RecognizeResponse response = await speechClient.RecognizeAsync(config, audio);
</code></pre></div>
  </div>
  <a id="Google_Cloud_Speech_V1_SpeechClient_RecognizeAsync_" data-uid="Google.Cloud.Speech.V1.SpeechClient.RecognizeAsync*"></a>
  <h4 id="Google_Cloud_Speech_V1_SpeechClient_RecognizeAsync_Google_Cloud_Speech_V1_RecognizeRequest_Google_Api_Gax_Grpc_CallSettings_" data-uid="Google.Cloud.Speech.V1.SpeechClient.RecognizeAsync(Google.Cloud.Speech.V1.RecognizeRequest,Google.Api.Gax.Grpc.CallSettings)">RecognizeAsync(RecognizeRequest, CallSettings)</h4>
  <div class="markdown level1 summary"><p>Performs synchronous speech recognition: receive results after all audio
has been sent and processed.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual Task&lt;RecognizeResponse&gt; RecognizeAsync(RecognizeRequest request, CallSettings callSettings = null)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.RecognizeRequest.html">RecognizeRequest</a></td>
        <td><span class="parametername">request</span></td>
        <td><p>The request object containing all of the parameters for the API call.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="Google.Api.Gax.Grpc.CallSettings.html">CallSettings</a></td>
        <td><span class="parametername">callSettings</span></td>
        <td><p>If not null, applies overrides to this RPC call.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Threading.Tasks.Task</span>&lt;<a class="xref" href="Google.Cloud.Speech.V1.RecognizeResponse.html">RecognizeResponse</a>&gt;</td>
        <td><p>A Task containing the RPC response.</p>
</td>
      </tr>
    </tbody>
  </table>
  <div>
  <h5 id="Google_Cloud_Speech_V1_SpeechClient_RecognizeAsync_Google_Cloud_Speech_V1_RecognizeRequest_Google_Api_Gax_Grpc_CallSettings__snippet">Sample code</h5>
  <div class="markdown level1"><pre><code class="lang-cs">// Create client
SpeechClient speechClient = await SpeechClient.CreateAsync();
// Initialize request argument(s)
RecognizeRequest request = new RecognizeRequest
{
    Config = new RecognitionConfig
             {
                 Encoding = RecognitionConfig.Types.AudioEncoding.Flac,
                 SampleRateHertz = 44100,
                 LanguageCode = &quot;en-US&quot;,
             },
    Audio = new RecognitionAudio
            {
                Uri = &quot;gs://bucket_name/file_name.flac&quot;,
            },
};
// Make the request
RecognizeResponse response = await speechClient.RecognizeAsync(request);
</code></pre></div>
  </div>
  <a id="Google_Cloud_Speech_V1_SpeechClient_ShutdownDefaultChannelsAsync_" data-uid="Google.Cloud.Speech.V1.SpeechClient.ShutdownDefaultChannelsAsync*"></a>
  <h4 id="Google_Cloud_Speech_V1_SpeechClient_ShutdownDefaultChannelsAsync" data-uid="Google.Cloud.Speech.V1.SpeechClient.ShutdownDefaultChannelsAsync">ShutdownDefaultChannelsAsync()</h4>
  <div class="markdown level1 summary"><p>Shuts down any channels automatically created by <a class="xref" href="Google.Cloud.Speech.V1.SpeechClient.html#Google_Cloud_Speech_V1_SpeechClient_Create_Google_Api_Gax_Grpc_ServiceEndpoint_Google_Cloud_Speech_V1_SpeechSettings_">Create(ServiceEndpoint, SpeechSettings)</a>
and <a class="xref" href="Google.Cloud.Speech.V1.SpeechClient.html#Google_Cloud_Speech_V1_SpeechClient_CreateAsync_Google_Api_Gax_Grpc_ServiceEndpoint_Google_Cloud_Speech_V1_SpeechSettings_">CreateAsync(ServiceEndpoint, SpeechSettings)</a>. Channels which weren&#39;t automatically
created are not affected.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static Task ShutdownDefaultChannelsAsync()</code></pre>
  </div>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Threading.Tasks.Task</span></td>
        <td><p>A task representing the asynchronous shutdown operation.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 id="Google_Cloud_Speech_V1_SpeechClient_ShutdownDefaultChannelsAsync_remarks">Remarks</h5>
  <div class="markdown level1 remarks"><p>After calling this method, further calls to <a class="xref" href="Google.Cloud.Speech.V1.SpeechClient.html#Google_Cloud_Speech_V1_SpeechClient_Create_Google_Api_Gax_Grpc_ServiceEndpoint_Google_Cloud_Speech_V1_SpeechSettings_">Create(ServiceEndpoint, SpeechSettings)</a>
and <a class="xref" href="Google.Cloud.Speech.V1.SpeechClient.html#Google_Cloud_Speech_V1_SpeechClient_CreateAsync_Google_Api_Gax_Grpc_ServiceEndpoint_Google_Cloud_Speech_V1_SpeechSettings_">CreateAsync(ServiceEndpoint, SpeechSettings)</a> will create new channels, which could
in turn be shut down by another call to this method.</p>
</div>
  <a id="Google_Cloud_Speech_V1_SpeechClient_StreamingRecognize_" data-uid="Google.Cloud.Speech.V1.SpeechClient.StreamingRecognize*"></a>
  <h4 id="Google_Cloud_Speech_V1_SpeechClient_StreamingRecognize_Google_Api_Gax_Grpc_CallSettings_Google_Api_Gax_Grpc_BidirectionalStreamingSettings_" data-uid="Google.Cloud.Speech.V1.SpeechClient.StreamingRecognize(Google.Api.Gax.Grpc.CallSettings,Google.Api.Gax.Grpc.BidirectionalStreamingSettings)">StreamingRecognize(CallSettings, BidirectionalStreamingSettings)</h4>
  <div class="markdown level1 summary"><p>Performs bidirectional streaming speech recognition: receive results while
sending audio. This method is only available via the gRPC API (not REST).</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public virtual SpeechClient.StreamingRecognizeStream StreamingRecognize(CallSettings callSettings = null, BidirectionalStreamingSettings streamingSettings = null)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.Api.Gax.Grpc.CallSettings.html">CallSettings</a></td>
        <td><span class="parametername">callSettings</span></td>
        <td><p>If not null, applies overrides to this RPC call.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="Google.Api.Gax.Grpc.BidirectionalStreamingSettings.html">BidirectionalStreamingSettings</a></td>
        <td><span class="parametername">streamingSettings</span></td>
        <td><p>If not null, applies streaming overrides to this RPC call.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h5 class="returns">Returns</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="Google.Cloud.Speech.V1.SpeechClient.StreamingRecognizeStream.html">SpeechClient.StreamingRecognizeStream</a></td>
        <td><p>The client-server stream.</p>
</td>
      </tr>
    </tbody>
  </table>
  <div>
  <h5 id="Google_Cloud_Speech_V1_SpeechClient_StreamingRecognize_Google_Api_Gax_Grpc_CallSettings_Google_Api_Gax_Grpc_BidirectionalStreamingSettings__snippet">Sample code</h5>
  <div class="markdown level1"><pre><code class="lang-cs">// Create client
SpeechClient speechClient = SpeechClient.Create();
// Initialize streaming call, retrieving the stream object
SpeechClient.StreamingRecognizeStream duplexStream = speechClient.StreamingRecognize();

// Sending requests and retrieving responses can be arbitrarily interleaved.
// Exact sequence will depend on client/server behavior.

// Create task to do something with responses from server
Task.Run(async () =&gt;
{
    IAsyncEnumerator&lt;StreamingRecognizeResponse&gt; responseStream = duplexStream.ResponseStream;
    while (await responseStream.MoveNext())
    {
        StreamingRecognizeResponse response = responseStream.Current;
        // Do something with streamed response
    }
    // The response stream has completed
});

// Send requests to the server
bool done = false;
while (!done)
{
    // Initialize a request
    StreamingRecognizeRequest request = new StreamingRecognizeRequest();
    // Stream a request to the server
    await duplexStream.WriteAsync(request);

    // Set &quot;done&quot; to true when sending requests is complete
}
// Complete writing requests to the stream
await duplexStream.WriteCompleteAsync();
</code></pre></div>
  </div>
</article>
          </div>
          
          <div class="hidden-sm col-md-2" role="complementary">
            <div class="sideaffix">
              <nav class="bs-docs-sidebar hidden-print hidden-xs hidden-sm affix" id="affix">
              <!-- <p><a class="back-to-top" href="#top">Back to top</a><p> -->
              </nav>
            </div>
          </div>
        </div>
      </div>
      
      <footer>
        <div class="grad-bottom"></div>
        <div class="footer">
          <div class="container">
            <span class="pull-right">
              <a href="#top">Back to top</a>
            </span>
             
            
          </div>
        </div>
      </footer>
    </div>
    
    <script type="text/javascript" src="../styles/docfx.vendor.js"></script>
    <script type="text/javascript" src="../styles/docfx.js"></script>
    <script type="text/javascript" src="../styles/main.js"></script>
  </body>
</html>
